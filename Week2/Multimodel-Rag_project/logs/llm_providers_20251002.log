2025-10-02 09:06:54 - llm_providers - INFO - __init__:57 - âœ… OpenAI provider initialized with model: gpt-3.5-turbo
2025-10-02 09:06:56 - llm_providers - ERROR - generate:104 - âŒ OpenAI generation failed: Connection error.
2025-10-02 09:10:41 - llm_providers - INFO - __init__:57 - âœ… OpenAI provider initialized with model: gpt-3.5-turbo
2025-10-02 09:10:42 - llm_providers - ERROR - generate:104 - âŒ OpenAI generation failed: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope********here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-10-02 09:13:23 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 09:13:27 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 96 tokens in 3.53s
2025-10-02 09:47:52 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 09:47:56 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 442 tokens in 0.99s
2025-10-02 09:47:57 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 462 tokens in 0.57s
2025-10-02 10:54:46 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 10:54:51 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 424 tokens in 1.58s
2025-10-02 10:54:51 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 462 tokens in 0.43s
2025-10-02 17:02:44 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 17:44:37 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 18:25:16 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 19:20:40 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 19:22:08 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 19:22:23 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 480 tokens in 9.51s
2025-10-02 19:24:42 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 19:25:00 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 411 tokens in 12.93s
2025-10-02 19:25:01 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 19:25:40 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 373 tokens in 34.10s
2025-10-02 19:25:40 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 19:27:15 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 419 tokens in 90.16s
2025-10-02 19:35:25 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 19:35:30 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 398 tokens in 0.67s
2025-10-02 19:35:32 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 516 tokens in 0.24s
2025-10-02 19:40:22 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 19:40:32 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 361 tokens in 5.71s
2025-10-02 19:40:33 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 361 tokens in 0.94s
2025-10-02 19:44:13 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 19:46:04 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 361 tokens in 104.06s
2025-10-02 19:51:12 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 19:51:12 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 42 tokens in 0.48s
2025-10-02 19:51:30 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 19:52:51 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 310 tokens in 78.11s
2025-10-02 19:52:52 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 19:53:08 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 318 tokens in 7.08s
2025-10-02 19:53:10 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 19:53:18 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 19:53:44 - llm_providers - ERROR - generate:365 - âŒ Groq generation failed: Request timed out.
2025-10-02 19:58:45 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 19:58:50 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 41 tokens in 4.22s
2025-10-02 22:52:09 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 22:52:10 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 41 tokens in 1.12s
2025-10-02 22:52:25 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 22:52:32 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 310 tokens in 0.44s
2025-10-02 22:52:33 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 22:52:40 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 270 tokens in 0.42s
2025-10-02 22:52:41 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 22:52:49 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-8b-instant
2025-10-02 22:52:52 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 308 tokens in 0.42s
2025-10-02 23:40:45 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-70b-versatile
2025-10-02 23:41:03 - llm_providers - ERROR - generate:365 - âŒ Groq generation failed: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-02 23:49:40 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.1-70b-versatile
2025-10-02 23:50:18 - llm_providers - ERROR - generate:365 - âŒ Groq generation failed: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}
2025-10-02 23:54:05 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.3-70b-versatile
2025-10-02 23:54:24 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 505 tokens in 1.09s
2025-10-02 23:57:25 - llm_providers - INFO - __init__:316 - âœ… Groq provider initialized with model: llama-3.3-70b-versatile
2025-10-02 23:57:48 - llm_providers - INFO - generate:360 - ğŸš€ Groq response: 447 tokens in 0.92s
